{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph_generator()\n",
    "\n",
    "\n",
    "## IMPLEMENTACIÓN\n",
    "\n",
    "  \n",
    "Esta función se encarga de archivar las observaciones (.csv) importadas desde Netlogo por fecha y hora, a la vez que interpreta los datos de salida gráficamente. \n",
    "El procedimiento para su implementación es el siguiente:\n",
    "\n",
    "1. Ejecutar el modelo en netlogo (uber.nlogo).\n",
    "2. Al finalizar cada simulación, se deberá ejecutar la función graph_generator() desde este notebook.\n",
    "3. La función guardara las respectivas graficas en directorios clasificados por fecha y hora, con su respectiva transición(gif).\n",
    "\n",
    "IMPORTANTE: Al finalizar cada simulación en Netlogo, presione DETENER en la ventana emergente, esto evitara que el programa se siga ejecutando en segundo plano y almacene grandes cantidades de información en el último archivo .csv generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from apng import APNG\n",
    "from IPython.display import Image\n",
    "from os import walk\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_generator():\n",
    "    #CREANDO DIRECTORIOS PARA CADA OBSERVACIÓN \n",
    "    fecha = time.strftime('%d-%m-%y')\n",
    "    hora = time.strftime('%H-%M-%S')\n",
    "    os.makedirs(str(fecha) +'/'+ str(hora))\n",
    "    os.makedirs(str(fecha) +'/'+ str(hora)+'/people/gif')\n",
    "    os.makedirs(str(fecha) +'/'+ str(hora)+'/drivers/gif')\n",
    "    \n",
    "    \n",
    "    #OBTENIENDO LOS CSV´S\n",
    "    def ls(ruta = '.'):\n",
    "        return next(walk(ruta))[2]\n",
    "    outs_files = ls()\n",
    "    outs_files.pop()\n",
    "    outs_files\n",
    "    csvs = [i for i in outs_files if \"_.csv\" in i]\n",
    "    csvs\n",
    "   \n",
    "    #MOVIENDOLOS A SU RESPECTIVA CARPETA DE OBSERVACIÓN \n",
    "    for file in csvs:\n",
    "        shutil.move(file, str(fecha) +'/'+ str(hora) )\n",
    "    shutil.move('_GENERAL_.csv', str(fecha) +'/'+ str(hora) )\n",
    "  \n",
    "    \n",
    "    #OBTENIENDO LOS DATOS DE LAS TORTUGAS EN LA NUEVA UBICACIÓN\n",
    "    def ls1(ruta = str(fecha) +'/'+ str(hora)):\n",
    "        return next(walk(ruta))[2]\n",
    "    outs_files1 = ls1()\n",
    "    outs_files1.pop()\n",
    "    outs_files1\n",
    "    csvs1 = [i for i in outs_files if \"data_turtles\" in i]\n",
    "    csvs1\n",
    "    \n",
    "    #ABRIENDO CSV´S Y FILTRANDO POR 'PEOPLE' Y 'DRIVERS'\n",
    "            \n",
    "    for file1 in csvs1:\n",
    "        d = pd.read_csv(str(fecha) +'/'+ str(hora)+'/'+file1, error_bad_lines=False)\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df2 = df[df['breed'] == 'people']\n",
    "        df3 = df[df['breed'] == 'drivers']\n",
    "        \n",
    "     #GENERANDO GRAFICAS Y GUARDANDOLAS EN DIRECTORIO  \n",
    "        #people\n",
    "        sns.jointplot(x=\"x\", y=\"y\", data=df2, kind=\"kde\", size=10)\n",
    "        plt.savefig(plt.savefig(str(fecha) +'/'+ str(hora)+'/people/people' + '_' + str(csvs1.index(file1)) + '.png'))\n",
    "        #drivers \n",
    "        sns.jointplot(x=\"x\", y=\"y\", data=df3, kind=\"kde\", size=10)\n",
    "        plt.savefig(plt.savefig(str(fecha) +'/'+ str(hora)+'/drivers/drivers' + '_' + str(csvs1.index(file1)) + '.png'))\n",
    "\n",
    "#ANIMACIÓN\n",
    "    \n",
    "    groups = ['df2','df3']\n",
    "    for n in groups:\n",
    "        #people\n",
    "        if groups[groups.index(n)] == 'df2':\n",
    "\n",
    "            def ls(ruta = str(fecha) +'/'+ str(hora)+'/people'):\n",
    "\n",
    "                return next(walk(ruta))[2]\n",
    "\n",
    "            images_people = ls()\n",
    "            images_people\n",
    "\n",
    "\n",
    "            for m in images_people:                           \n",
    "                img = str(str(fecha) +'/'+ str(hora)+'/people/' + m)       \n",
    "                img\n",
    "                graphs = images_people\n",
    "                graphs[int(images_people.index(m))] = img                        \n",
    "\n",
    "            APNG.from_files(graphs, delay = 400).save(str(fecha) +'/'+ str(hora)+'/people/gif/trans_p_'+str(fecha) +'_'+ str(hora)+'.png')\n",
    "            Image(filename = str(fecha) +'/'+ str(hora)+'/people/gif/trans_p_'+str(fecha) +'_'+ str(hora)+'.png')\n",
    "        #drivers\n",
    "        elif groups[groups.index(n)] == 'df3':\n",
    "\n",
    "            def ls(ruta = str(fecha) +'/'+ str(hora)+'/drivers'):\n",
    "\n",
    "                return next(walk(ruta))[2]\n",
    "\n",
    "            images_drivers = ls()\n",
    "            images_drivers\n",
    "\n",
    "\n",
    "            for x in images_drivers:                           \n",
    "                immg = str(str(fecha) +'/'+ str(hora)+'/drivers/' + x)       \n",
    "                immg\n",
    "                graphs = images_drivers\n",
    "                graphs[int(images_drivers.index(x))] = immg                        \n",
    "\n",
    "            APNG.from_files(graphs,delay=400).save(str(fecha) +'/'+ str(hora)+'/drivers/gif/trans_d_'+str(fecha) +'_'+ str(hora)+'.png')\n",
    "            Image(filename=str(fecha) +'/'+ str(hora)+'/drivers/gif/trans_d_'+str(fecha) +'_'+ str(hora)+'.png')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18-jun-2018_12-16-48_GENERAL_.csv',\n",
       " '18-jun-2018_12-16-48__0_.csv',\n",
       " '18-jun-2018_12-16-48__100_.csv',\n",
       " '18-jun-2018_12-16-48__10_.csv',\n",
       " '18-jun-2018_12-16-48__20_.csv',\n",
       " '18-jun-2018_12-16-48__30_.csv',\n",
       " '18-jun-2018_12-16-48__40_.csv',\n",
       " '18-jun-2018_12-16-48__50_.csv',\n",
       " '18-jun-2018_12-16-48__60_.csv',\n",
       " '18-jun-2018_12-16-48__70_.csv',\n",
       " '18-jun-2018_12-16-48__80_.csv',\n",
       " '18-jun-2018_12-16-48__90_.csv',\n",
       " '18-jun-2018_12-19-11_GENERAL_.csv',\n",
       " '18-jun-2018_12-19-11__0_.csv',\n",
       " '18-jun-2018_12-19-11__100_.csv',\n",
       " '18-jun-2018_12-19-11__10_.csv',\n",
       " '18-jun-2018_12-19-11__20_.csv',\n",
       " '18-jun-2018_12-19-11__30_.csv',\n",
       " '18-jun-2018_12-19-11__40_.csv',\n",
       " '18-jun-2018_12-19-11__50_.csv',\n",
       " '18-jun-2018_12-19-11__60_.csv',\n",
       " '18-jun-2018_12-19-11__70_.csv',\n",
       " '18-jun-2018_12-19-11__80_.csv',\n",
       " '18-jun-2018_12-19-11__90_.csv',\n",
       " '18-jun-2018_12-21-16_GENERAL_.csv',\n",
       " '18-jun-2018_12-21-16__0_.csv',\n",
       " '18-jun-2018_12-21-16__100_.csv',\n",
       " '18-jun-2018_12-21-16__10_.csv',\n",
       " '18-jun-2018_12-21-16__20_.csv',\n",
       " '18-jun-2018_12-21-16__30_.csv',\n",
       " '18-jun-2018_12-21-16__40_.csv',\n",
       " '18-jun-2018_12-21-16__50_.csv',\n",
       " '18-jun-2018_12-21-16__60_.csv',\n",
       " '18-jun-2018_12-21-16__70_.csv',\n",
       " '18-jun-2018_12-21-16__80_.csv',\n",
       " '18-jun-2018_12-21-16__90_.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #OBTENIENDO LOS CSV´S\n",
    "def ls(ruta = '.'):\n",
    "    return next(walk(ruta))[2]\n",
    "outs_files = ls()\n",
    "outs_files.pop()\n",
    "outs_files\n",
    "csvs = [i for i in outs_files if \"_.csv\" in i]\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] No se puede crear un archivo que ya existe: '18-jun-2018/12-16-48'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e988ebb0e3dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m      \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] No se puede crear un archivo que ya existe: '18-jun-2018/12-16-48'"
     ]
    }
   ],
   "source": [
    "for t in csvs:\n",
    "    if\n",
    "     os.makedirs(str(t[0:11]) +'/'+ str(t[12:20]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
